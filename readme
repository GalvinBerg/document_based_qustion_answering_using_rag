:

ğŸ“˜ Document Question Answering System using RAG

This project implements a Document-based Question Answering (QA) System using Retrieval-Augmented Generation (RAG).
It allows users to upload documents (PDFs), index them into a vector database, and then ask natural language questions. The system retrieves the most relevant chunks and generates precise, context-aware answers.

ğŸ”§ Features

ğŸ“„ Upload and process PDF documents.

âœ‚ï¸ Split documents into chunks for better retrieval.

ğŸ” Store embeddings in a FAISS vector database.

ğŸ§  Use HuggingFace embeddings for semantic search.

ğŸ¤– Retrieve relevant context and generate answers via LLM (RAG pipeline).

ğŸŒ FastAPI backend for seamless API access.

ğŸ› ï¸ Tech Stack

Backend Framework: FastAPI

Language Models: HuggingFace / OpenAI / Ollama (configurable)

Vector Store: FAISS

Embeddings: HuggingFace Transformers

Document Processing: LangChain (text splitting & ingestion)
